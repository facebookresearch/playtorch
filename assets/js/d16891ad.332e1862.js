"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3441],{3905:(e,t,r)=>{r.r(t),r.d(t,{MDXContext:()=>m,MDXProvider:()=>s,mdx:()=>f,useMDXComponents:()=>c,withMDXComponents:()=>p});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(){return i=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var r=arguments[t];for(var n in r)Object.prototype.hasOwnProperty.call(r,n)&&(e[n]=r[n])}return e},i.apply(this,arguments)}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function d(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var m=n.createContext({}),p=function(e){return function(t){var r=c(t.components);return n.createElement(e,i({},t,{components:r}))}},c=function(e){var t=n.useContext(m),r=t;return e&&(r="function"==typeof e?e(t):d(d({},t),e)),r},s=function(e){var t=c(e.components);return n.createElement(m.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},x=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,i=e.originalType,o=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),p=c(r),s=a,x=p["".concat(o,".").concat(s)]||p[s]||u[s]||i;return r?n.createElement(x,d(d({ref:t},m),{},{components:r})):n.createElement(x,d({ref:t},m))}));function f(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=r.length,o=new Array(i);o[0]=x;var d={};for(var l in t)hasOwnProperty.call(t,l)&&(d[l]=t[l]);d.originalType=e,d.mdxType="string"==typeof e?e:a,o[1]=d;for(var m=2;m<i;m++)o[m]=r[m];return n.createElement.apply(null,o)}return n.createElement.apply(null,r)}x.displayName="MDXCreateElement"},72772:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>d,toc:()=>m});var n=r(83117),a=(r(67294),r(3905));const i={id:"text_wordpiecetokenizer.wordpiecetokenizer",title:"Class: WordPieceTokenizer",sidebar_label:"WordPieceTokenizer",custom_edit_url:null},o=void 0,d={unversionedId:"api/core/classes/text_wordpiecetokenizer.wordpiecetokenizer",id:"api/core/classes/text_wordpiecetokenizer.wordpiecetokenizer",title:"Class: WordPieceTokenizer",description:"text/WordpieceTokenizer.WordPieceTokenizer",source:"@site/docs/api/core/classes/text_wordpiecetokenizer.wordpiecetokenizer.md",sourceDirName:"api/core/classes",slug:"/api/core/classes/text_wordpiecetokenizer.wordpiecetokenizer",permalink:"/docs/next/api/core/classes/text_wordpiecetokenizer.wordpiecetokenizer",draft:!1,editUrl:null,tags:[],version:"current",frontMatter:{id:"text_wordpiecetokenizer.wordpiecetokenizer",title:"Class: WordPieceTokenizer",sidebar_label:"WordPieceTokenizer",custom_edit_url:null},sidebar:"api",previous:{title:"BasicTokenizer",permalink:"/docs/next/api/core/classes/text_basictokenizer.basictokenizer"},next:{title:"Audio",permalink:"/docs/next/api/core/interfaces/audio_audiomodule.audio"}},l={},m=[{value:"Constructors",id:"constructors",level:2},{value:"constructor",id:"constructor",level:3},{value:"Parameters",id:"parameters",level:4},{value:"Defined in",id:"defined-in",level:4},{value:"Methods",id:"methods",level:2},{value:"decode",id:"decode",level:3},{value:"Parameters",id:"parameters-1",level:4},{value:"Returns",id:"returns",level:4},{value:"Defined in",id:"defined-in-1",level:4},{value:"encode",id:"encode",level:3},{value:"Parameters",id:"parameters-2",level:4},{value:"Returns",id:"returns-1",level:4},{value:"Defined in",id:"defined-in-2",level:4},{value:"tokenize",id:"tokenize",level:3},{value:"Parameters",id:"parameters-3",level:4},{value:"Returns",id:"returns-2",level:4},{value:"Defined in",id:"defined-in-3",level:4}],p={toc:m};function c(e){let{components:t,...r}=e;return(0,a.mdx)("wrapper",(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,a.mdx)("p",null,(0,a.mdx)("a",{parentName:"p",href:"/docs/next/api/core/modules/text_wordpiecetokenizer"},"text/WordpieceTokenizer"),".WordPieceTokenizer"),(0,a.mdx)("h2",{id:"constructors"},"Constructors"),(0,a.mdx)("h3",{id:"constructor"},"constructor"),(0,a.mdx)("p",null,"\u2022 ",(0,a.mdx)("strong",{parentName:"p"},"new WordPieceTokenizer"),"(",(0,a.mdx)("inlineCode",{parentName:"p"},"config"),")"),(0,a.mdx)("p",null,"Construct a tokenizer with a WordPieceTokenizer object."),(0,a.mdx)("h4",{id:"parameters"},"Parameters"),(0,a.mdx)("table",null,(0,a.mdx)("thead",{parentName:"table"},(0,a.mdx)("tr",{parentName:"thead"},(0,a.mdx)("th",{parentName:"tr",align:"left"},"Name"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Type"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Description"))),(0,a.mdx)("tbody",{parentName:"table"},(0,a.mdx)("tr",{parentName:"tbody"},(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"config")),(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("a",{parentName:"td",href:"/docs/next/api/core/modules/text_wordpiecetokenizer#wordpiecetokenizerconfig"},"WordPieceTokenizerConfig")),(0,a.mdx)("td",{parentName:"tr",align:"left"},"a tokenizer configuration object that specify the vocabulary and special tokens, etc.")))),(0,a.mdx)("h4",{id:"defined-in"},"Defined in"),(0,a.mdx)("p",null,(0,a.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/playtorch/blob/d8eb616/react-native-pytorch-core/src/text/WordpieceTokenizer.ts#L26"},"text/WordpieceTokenizer.ts:26")),(0,a.mdx)("h2",{id:"methods"},"Methods"),(0,a.mdx)("h3",{id:"decode"},"decode"),(0,a.mdx)("p",null,"\u25b8 ",(0,a.mdx)("strong",{parentName:"p"},"decode"),"(",(0,a.mdx)("inlineCode",{parentName:"p"},"tokenIds"),"): ",(0,a.mdx)("inlineCode",{parentName:"p"},"string")),(0,a.mdx)("p",null,"Decode an array of tokenIds to a string using the vocabulary"),(0,a.mdx)("h4",{id:"parameters-1"},"Parameters"),(0,a.mdx)("table",null,(0,a.mdx)("thead",{parentName:"table"},(0,a.mdx)("tr",{parentName:"thead"},(0,a.mdx)("th",{parentName:"tr",align:"left"},"Name"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Type"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Description"))),(0,a.mdx)("tbody",{parentName:"table"},(0,a.mdx)("tr",{parentName:"tbody"},(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"tokenIds")),(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"number"),"[]"),(0,a.mdx)("td",{parentName:"tr",align:"left"},"an array of tokenIds derived from the output of model")))),(0,a.mdx)("h4",{id:"returns"},"Returns"),(0,a.mdx)("p",null,(0,a.mdx)("inlineCode",{parentName:"p"},"string")),(0,a.mdx)("p",null,"a string decoded from the output of the model"),(0,a.mdx)("h4",{id:"defined-in-1"},"Defined in"),(0,a.mdx)("p",null,(0,a.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/playtorch/blob/d8eb616/react-native-pytorch-core/src/text/WordpieceTokenizer.ts#L143"},"text/WordpieceTokenizer.ts:143")),(0,a.mdx)("hr",null),(0,a.mdx)("h3",{id:"encode"},"encode"),(0,a.mdx)("p",null,"\u25b8 ",(0,a.mdx)("strong",{parentName:"p"},"encode"),"(",(0,a.mdx)("inlineCode",{parentName:"p"},"text"),"): ",(0,a.mdx)("inlineCode",{parentName:"p"},"number"),"[]"),(0,a.mdx)("p",null,"Encode the raw input to a NLP model to an array of number, which is tensorizable."),(0,a.mdx)("h4",{id:"parameters-2"},"Parameters"),(0,a.mdx)("table",null,(0,a.mdx)("thead",{parentName:"table"},(0,a.mdx)("tr",{parentName:"thead"},(0,a.mdx)("th",{parentName:"tr",align:"left"},"Name"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Type"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Description"))),(0,a.mdx)("tbody",{parentName:"table"},(0,a.mdx)("tr",{parentName:"tbody"},(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"text")),(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"string")),(0,a.mdx)("td",{parentName:"tr",align:"left"},"The raw input of the model")))),(0,a.mdx)("h4",{id:"returns-1"},"Returns"),(0,a.mdx)("p",null,(0,a.mdx)("inlineCode",{parentName:"p"},"number"),"[]"),(0,a.mdx)("p",null,"An array of number, which can then be used to create a tensor as model input with the torch.tensor API"),(0,a.mdx)("h4",{id:"defined-in-2"},"Defined in"),(0,a.mdx)("p",null,(0,a.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/playtorch/blob/d8eb616/react-native-pytorch-core/src/text/WordpieceTokenizer.ts#L132"},"text/WordpieceTokenizer.ts:132")),(0,a.mdx)("hr",null),(0,a.mdx)("h3",{id:"tokenize"},"tokenize"),(0,a.mdx)("p",null,"\u25b8 ",(0,a.mdx)("strong",{parentName:"p"},"tokenize"),"(",(0,a.mdx)("inlineCode",{parentName:"p"},"text"),"): ",(0,a.mdx)("inlineCode",{parentName:"p"},"string"),"[]"),(0,a.mdx)("p",null,"Tokenizes a piece of text into its word pieces.\nThis uses a greedy longest-match-first algorithm to perform tokenization using the given vocabulary."),(0,a.mdx)("h4",{id:"parameters-3"},"Parameters"),(0,a.mdx)("table",null,(0,a.mdx)("thead",{parentName:"table"},(0,a.mdx)("tr",{parentName:"thead"},(0,a.mdx)("th",{parentName:"tr",align:"left"},"Name"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Type"),(0,a.mdx)("th",{parentName:"tr",align:"left"},"Description"))),(0,a.mdx)("tbody",{parentName:"table"},(0,a.mdx)("tr",{parentName:"tbody"},(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"text")),(0,a.mdx)("td",{parentName:"tr",align:"left"},(0,a.mdx)("inlineCode",{parentName:"td"},"string")),(0,a.mdx)("td",{parentName:"tr",align:"left"},"the raw input of the model")))),(0,a.mdx)("h4",{id:"returns-2"},"Returns"),(0,a.mdx)("p",null,(0,a.mdx)("inlineCode",{parentName:"p"},"string"),"[]"),(0,a.mdx)("p",null,"an array of tokens in vocabulary representing the input text."),(0,a.mdx)("h4",{id:"defined-in-3"},"Defined in"),(0,a.mdx)("p",null,(0,a.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/playtorch/blob/d8eb616/react-native-pytorch-core/src/text/WordpieceTokenizer.ts#L71"},"text/WordpieceTokenizer.ts:71")))}c.isMDXComponent=!0}}]);